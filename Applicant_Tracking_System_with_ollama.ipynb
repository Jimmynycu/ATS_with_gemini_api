{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPrW/LfRDe4WDFvCduJoIO7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jimmynycu/ATS_with_gemini_api/blob/main/Applicant_Tracking_System_with_ollama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyautogen pypdf pandas openpyxl python-dotenv autogen --quiet\n",
        "\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSVhgfaEUdd7",
        "outputId": "553728ba-9e74-43da-eeb3-0c7c0e67e195"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/310.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.0/834.0 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.1/119.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h>>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import autogen\n",
        "import json\n",
        "import pandas as pd\n",
        "from pypdf import PdfReader\n",
        "import os\n",
        "import asyncio"
      ],
      "metadata": {
        "id": "g5SHdREyVU90"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pid = os.fork()\n",
        "if pid == 0:\n",
        "    os.execv('/usr/local/bin/ollama', ['ollama', 'serve'])\n",
        "else:\n",
        "    print(\"Ollama server started in the background.\")\n",
        "\n",
        "await asyncio.sleep(5)\n",
        "!ollama pull llama3:instruct &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF-F50eSUjwP",
        "outputId": "9477c304-3c98-4129-8542-5c240462b06d"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1792677764.py:1: DeprecationWarning: This process (pid=1140) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ollama server started in the background.\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbc3c5c8",
        "outputId": "3dd1eb3a-5991-4b4e-c3cd-4d8fc3f3fd12"
      },
      "source": [
        "import httpx\n",
        "import json # Import json to potentially print the response data\n",
        "\n",
        "ollama_chat_url = \"http://127.0.0.1:11434/api/chat\"\n",
        "model_name = \"llama3:instruct\"\n",
        "prompt_message = {\"role\": \"user\", \"content\": \"Are you ready?\"}\n",
        "payload = {\n",
        "    \"model\": model_name,\n",
        "    \"messages\": [prompt_message],\n",
        "    \"stream\": False\n",
        "}\n",
        "\n",
        "print(f\"Sending simple test prompt to {ollama_chat_url}...\")\n",
        "\n",
        "# Send the POST request\n",
        "response = httpx.post(ollama_chat_url, json=payload, timeout=10.0) # Added a basic timeout\n",
        "\n",
        "# Print the status code and response text/json\n",
        "print(f\"Response Status Code: {response.status_code}\")\n",
        "try:\n",
        "    # Attempt to parse and print JSON if possible\n",
        "    print(\"Response Body (JSON if available):\")\n",
        "    print(json.dumps(response.json(), indent=2))\n",
        "except json.JSONDecodeError:\n",
        "    # Otherwise, print raw text\n",
        "    print(\"Response Body (Text):\")\n",
        "    print(response.text)\n",
        "\n",
        "print(\"\\nSimple test complete.\")"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sending simple test prompt to http://127.0.0.1:11434/api/chat...\n",
            "Response Status Code: 200\n",
            "Response Body (JSON if available):\n",
            "{\n",
            "  \"model\": \"llama3:instruct\",\n",
            "  \"created_at\": \"2025-09-09T19:48:09.853287692Z\",\n",
            "  \"message\": {\n",
            "    \"role\": \"assistant\",\n",
            "    \"content\": \"I'm always ready! What's next?\"\n",
            "  },\n",
            "  \"done_reason\": \"stop\",\n",
            "  \"done\": true,\n",
            "  \"total_duration\": 3172958254,\n",
            "  \"load_duration\": 2702521389,\n",
            "  \"prompt_eval_count\": 14,\n",
            "  \"prompt_eval_duration\": 151055268,\n",
            "  \"eval_count\": 10,\n",
            "  \"eval_duration\": 318451398\n",
            "}\n",
            "\n",
            "Simple test complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_list=[\n",
        "    {\n",
        "        \"model\": \"llama3:instruct\",\n",
        "        \"base_url\": \"http://127.0.0.1:11434/v1\",\n",
        "        \"api_key\": \"ollama\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "wNCOVhUDUywl"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "llm_config = {\n",
        "        \"config_list\": config_list,\n",
        "        \"temperature\": 0.0\n",
        "        }"
      ],
      "metadata": {
        "id": "s5ya_ZljU3gN"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser_agent = autogen.ConversableAgent(\n",
        "    name=\"ResumeParserAgent\",\n",
        "    system_message=\"\"\"You are an expert HR data extraction specialist.\n",
        "            Your ONLY task is to parse resume text into a structured JSON format. You must STRICTLY and LITERALLY adhere to the following rules:\n",
        "            1.  Begin your response with a ```json code block.\n",
        "            2.  Provide the complete, raw JSON object inside the code block.\n",
        "            3.  End your response with the closing ``` code block.\n",
        "            4.  Your entire response must consist of NOTHING but the JSON object enclosed within the opening and closing ```json``` code blocks.\n",
        "            5.  DO NOT add any other text, commentary, greetings, or explanations before, after, or inside the code block.\n",
        "            \"\"\",\n",
        "            llm_config=llm_config,\n",
        "            human_input_mode=\"NEVER\",\n",
        "    )\n",
        "\n",
        "# Function to check for the termination condition\n",
        "def is_json_termination_msg(message):\n",
        "    content = message.get(\"content\", \"\")\n",
        "    print(f\"Checking message for termination: {content}\")\n",
        "    # This checks for a code block that starts with \"```json\" and ends with \"```\".\n",
        "    return content.startswith(\"```json\") and content.endswith(\"```\")\n",
        "\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"UserProxyAgent\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False},\n",
        "    is_termination_msg=is_json_termination_msg,\n",
        "    max_consecutive_auto_reply=10,\n",
        ")"
      ],
      "metadata": {
        "id": "yg6ALLuYY6p8"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF\n",
        "pdf_path = \"Jimmy_CV.pdf\"\n",
        "raw_resume_text = \"\"\n",
        "try:\n",
        "    reader = PdfReader(pdf_path)\n",
        "    for page in reader.pages:\n",
        "        raw_resume_text += page.extract_text() or \"\"\n",
        "    print(\"PDF text extracted successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{pdf_path}' not found.\")\n",
        "else:\n",
        "    # --- Agentic Workflow ---\n",
        "    user_proxy.initiate_chat(\n",
        "        parser_agent,\n",
        "        message=f\"\"\"\n",
        "            Please parse the following resume text into the required JSON format.\n",
        "\n",
        "            JSON Schema:\n",
        "            {{\n",
        "              \"contact_information\": {{ \"name\": \"string\", \"email\": \"string\", \"phone\": \"string\", \"location\": \"string\", \"links\": [\"string\"] }},\n",
        "              \"professional_summary\": \"string\",\n",
        "              \"skills\": [\"string\"],\n",
        "              \"work_experience\": [ {{ \"job_title\": \"string\", \"company\": \"string\", \"location\": \"string\", \"responsibilities\": [\"string\"] }} ],\n",
        "              \"education\": [ {{ \"degree\": \"string\", \"institution\": \"string\", \"location\": \"string\" }} ],\n",
        "              \"personal_projects\": [ {{ \"project_name\": \"string\", \"description\": \"string\" }} ]\n",
        "            }}\n",
        "\n",
        "            Resume Text:\n",
        "            ---\n",
        "            {raw_resume_text}\n",
        "            ---\n",
        "            \"\"\",\n",
        "    )\n",
        "\n",
        "    # --- Save Output ---\n",
        "    json_string = None\n",
        "    last_message = user_proxy.last_message(parser_agent)\n",
        "\n",
        "    if last_message and \"```json\" in last_message[\"content\"]:\n",
        "        json_string = last_message[\"content\"].split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "    if json_string:\n",
        "        print(\"\\n LLM generated the structured JSON. Now saving to Excel...\")\n",
        "        try:\n",
        "            data = json.loads(json_string)\n",
        "            with pd.ExcelWriter(\"resume_data.xlsx\", engine='openpyxl') as writer:\n",
        "\n",
        "                # 1. Save Contact Information\n",
        "                contact_info_df = pd.DataFrame([data.get('contact_information', {})])\n",
        "                contact_info_df.to_excel(writer, sheet_name='Contact_Info', index=False)\n",
        "\n",
        "                # 2. Save Professional Summary\n",
        "                professional_summary_df = pd.DataFrame({'summary': [data.get('professional_summary', '')]})\n",
        "                professional_summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "                # 3. Save Skills\n",
        "                skills_list = data.get('skills', [])\n",
        "                skills_df = pd.DataFrame(skills_list, columns=['Skill'])\n",
        "                skills_df.to_excel(writer, sheet_name='Skills', index=False)\n",
        "\n",
        "                # 4. Save Work Experience\n",
        "                work_experience_list = data.get('work_experience', [])\n",
        "                work_experience_df = pd.DataFrame(work_experience_list)\n",
        "                work_experience_df.to_excel(writer, sheet_name='Work_Experience', index=False)\n",
        "\n",
        "                # 5. Save Education\n",
        "                education_list = data.get('education', [])\n",
        "                education_df = pd.DataFrame(education_list)\n",
        "                education_df.to_excel(writer, sheet_name='Education', index=False)\n",
        "\n",
        "                # 6. Save Personal Projects\n",
        "                personal_projects_list = data.get('personal_projects', [])\n",
        "                personal_projects_df = pd.DataFrame(personal_projects_list)\n",
        "                personal_projects_df.to_excel(writer, sheet_name='Personal_Projects', index=False)\n",
        "\n",
        "            print(\"Excel file 'resume_data.xlsx' saved successfully. You can find it in the file browser.\")\n",
        "\n",
        "        except (json.JSONDecodeError, KeyError) as e:\n",
        "            print(f\"Error: Could not process the JSON from the LLM. Error: {e}\")\n",
        "    else:\n",
        "        print(\"\\nError: Could not find the JSON output from the LLM conversation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jYImht6Y9Yn",
        "outputId": "9aae3417-c246-4109-e2c4-ecf002d6e723"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF text extracted successfully.\n",
            "UserProxyAgent (to ResumeParserAgent):\n",
            "\n",
            "\n",
            "            Please parse the following resume text into the required JSON format.\n",
            "\n",
            "            JSON Schema:\n",
            "            {\n",
            "              \"contact_information\": { \"name\": \"string\", \"email\": \"string\", \"phone\": \"string\", \"location\": \"string\", \"links\": [\"string\"] },\n",
            "              \"professional_summary\": \"string\",\n",
            "              \"skills\": [\"string\"],\n",
            "              \"work_experience\": [ { \"job_title\": \"string\", \"company\": \"string\", \"location\": \"string\", \"responsibilities\": [\"string\"] } ],\n",
            "              \"education\": [ { \"degree\": \"string\", \"institution\": \"string\", \"location\": \"string\" } ],\n",
            "              \"personal_projects\": [ { \"project_name\": \"string\", \"description\": \"string\" } ]\n",
            "            }\n",
            "\n",
            "            Resume Text:\n",
            "            ---\n",
            "            JIMMY LIU\n",
            "Taiwan Taipei⋄ +886 978768367 ⋄ jimmyliu.ii12@nycu.edu.tw ⋄ Github: Jimmynyu\n",
            "PROFESSIONAL SUMMARY\n",
            "AI/ML engineer with specialized expertise in LLM quantization and foundation models. Seeking an opportunity to\n",
            "contribute to AI development, leveraging LLM optimization and deployment background.\n",
            "SKILLS\n",
            "Programming Languages:\n",
            "• Agent Coding\n",
            "• Python (Advanced)\n",
            "• PyTorch & TensorFlow\n",
            "• Git version control\n",
            "AI/ML Expertise:\n",
            "• LLM fine-tuning & deployment\n",
            "• Foundation model dev.\n",
            "• Deep learning optimization\n",
            "• Quantitative analysis\n",
            "Additional Technical Skills:\n",
            "• Linux administration\n",
            "• Verilog\n",
            "• Communication\n",
            "• English TOEIC 935\n",
            "EXPERIENCE\n",
            "EDA Software Engineer\n",
            "MediaTek – Hsinchu, Taiwan\n",
            "• Implemented and optimized LLM-based workflows, achieving 50% acceleration in processing speed.\n",
            "• Developed and maintained Python-based automation tools for workflow optimization.\n",
            "• Created comprehensive technical documentation and user guides for cross-team collaboration.\n",
            "• Utilized Git for version control and collaborative development.\n",
            "Impedance Engineer\n",
            "Broadcom – Hsinchu, Taiwan\n",
            "• Designed and implemented new automated workflow system using Python, reducing processing time by 70%.\n",
            "• Led technical documentation efforts and knowledge sharing initiatives across teams.\n",
            "• Collaborated with cross-functional teams to optimize design solutions.\n",
            "EDUCATION\n",
            "Master’s Degree: Institute of Artificial Intelligence Innovation\n",
            "National Yang Ming Chiao Tung University– Hsinchu, Taiwan\n",
            "• Focusing on LLM calibration; coursework in machine learning & deep learning fundamentals.\n",
            "• Experience in LLM fine-tuning, Retrieval Augmented Generation (RAG), and test bench.\n",
            "• Designed software simulations of AI models to guide hardware acceleration development.\n",
            "PERSONAL PROJECTS\n",
            "• Algorithmic Trading Agent for TSMC Stock Using Deep Reinforcement Learning\n",
            "– Developed PPO agent withFinRL based on historical market data and technical indicators.\n",
            "– Engineered a data pipelineon time series data and evaluate the agent’s strategy via a multi-year backtest,\n",
            "analyzing performance with metrics likeSharpe Ratioand Max Drawdown.\n",
            "• YouTube Trend Analysis & NLP Application:\n",
            "– Developed system extracting/analyzing YouTube comments (YouTube Data API).\n",
            "– Applied Hugging Face Transformers (sentiment) & TF-IDF (keywords).\n",
            "• LLM-Powered Data Retrieval & Filtering:\n",
            "– Engineered LLM solution with function calls for targeted YouTube video search.\n",
            "– Implemented regional/keyword-based trend filtering & automated comment data fetching.\n",
            "• Multi-Agent AI Resume Parser & Analyzer:\n",
            "– Engineered LLM solution to extract information and save in excel format.\n",
            "– Analyze the information in excel to output the summary of the resume.\n",
            "            ---\n",
            "            \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-09 19:26:03] {695} WARNING - Model llama3:instruct is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model llama3:instruct is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResumeParserAgent (to UserProxyAgent):\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"contact_information\": {\n",
            "    \"name\": \"JIMMY LIU\",\n",
            "    \"email\": \"jimmyliu.ii12@nycu.edu.tw\",\n",
            "    \"phone\": \"+886 978768367\",\n",
            "    \"location\": \"Taiwan Taipei\",\n",
            "    \"links\": [\"Github: Jimmynyu\"]\n",
            "  },\n",
            "  \"professional_summary\": \"AI/ML engineer with specialized expertise in LLM quantization and foundation models. Seeking an opportunity to contribute to AI development, leveraging LLM optimization and deployment background.\",\n",
            "  \"skills\": [\n",
            "    \"Agent Coding\",\n",
            "    \"Python (Advanced)\",\n",
            "    \"PyTorch & TensorFlow\",\n",
            "    \"Git version control\",\n",
            "    \"LLM fine-tuning & deployment\",\n",
            "    \"Foundation model dev.\",\n",
            "    \"Deep learning optimization\",\n",
            "    \"Quantitative analysis\",\n",
            "    \"Linux administration\",\n",
            "    \"Verilog\",\n",
            "    \"Communication\",\n",
            "    \"English TOEIC 935\"\n",
            "  ],\n",
            "  \"work_experience\": [\n",
            "    {\n",
            "      \"job_title\": \"EDA Software Engineer\",\n",
            "      \"company\": \"MediaTek\",\n",
            "      \"location\": \"Hsinchu, Taiwan\",\n",
            "      \"responsibilities\": [\n",
            "        \"Implemented and optimized LLM-based workflows, achieving 50% acceleration in processing speed.\",\n",
            "        \"Developed and maintained Python-based automation tools for workflow optimization.\",\n",
            "        \"Created comprehensive technical documentation and user guides for cross-team collaboration.\",\n",
            "        \"Utilized Git for version control and collaborative development.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"job_title\": \"Impedance Engineer\",\n",
            "      \"company\": \"Broadcom\",\n",
            "      \"location\": \"Hsinchu, Taiwan\",\n",
            "      \"responsibilities\": [\n",
            "        \"Designed and implemented new automated workflow system using Python, reducing processing time by 70%.\",\n",
            "        \"Led technical documentation efforts and knowledge sharing initiatives across teams.\",\n",
            "        \"Collaborated with cross-functional teams to optimize design solutions.\"\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"Master’s Degree\",\n",
            "      \"institution\": \"Institute of Artificial Intelligence Innovation, National Yang Ming Chiao Tung University\",\n",
            "      \"location\": \"Hsinchu, Taiwan\"\n",
            "    }\n",
            "  ],\n",
            "  \"personal_projects\": [\n",
            "    {\n",
            "      \"project_name\": \"Algorithmic Trading Agent for TSMC Stock Using Deep Reinforcement Learning\",\n",
            "      \"description\": \"Developed PPO agent with FinRL based on historical market data and technical indicators. Engineered a data pipeline on time series data and evaluate the agent’s strategy via a multi-year backtest, analyzing performance with metrics like Sharpe Ratio and Max Drawdown.\"\n",
            "    },\n",
            "    {\n",
            "      \"project_name\": \"YouTube Trend Analysis & NLP Application\",\n",
            "      \"description\": \"Developed system extracting/analyzing YouTube comments (YouTube Data API). Applied Hugging Face Transformers (sentiment) & TF-IDF (keywords).\"\n",
            "    },\n",
            "    {\n",
            "      \"project_name\": \"LLM-Powered Data Retrieval & Filtering\",\n",
            "      \"description\": \"Engineered LLM solution with function calls for targeted YouTube video search. Implemented regional/keyword-based trend filtering & automated comment data fetching.\"\n",
            "    },\n",
            "    {\n",
            "      \"project_name\": \"Multi-Agent AI Resume Parser & Analyzer\",\n",
            "      \"description\": \"Engineered LLM solution to extract information and save in excel format. Analyze the information in excel to output the summary of the resume.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (904011c5-8640-4576-856d-33471de646bf): Termination message condition on agent 'UserProxyAgent' met\n",
            "\n",
            "✅ LLM generated the structured JSON. Now saving to Excel...\n",
            "💾 Excel file 'resume_data.xlsx' saved successfully. You can find it in the file browser.\n",
            "\n",
            "🎉 Part 1 Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_from_excel(file_path: str):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Error: The file '{file_path}' was not found.\")\n",
        "        return None\n",
        "    print(f\" Loading structured data from '{file_path}'...\")\n",
        "    xls = pd.ExcelFile(file_path)\n",
        "    data = {}\n",
        "    data['contact_information'] = pd.read_excel(xls, 'Contact_Info').fillna('').to_dict('records')[0]\n",
        "    data['professional_summary'] = pd.read_excel(xls, 'Summary').fillna('').to_dict('records')[0]['summary']\n",
        "    data['skills'] = pd.read_excel(xls, 'Skills')['Skill'].dropna().tolist()\n",
        "    data['work_experience'] = pd.read_excel(xls, 'Work_Experience').fillna('').to_dict('records')\n",
        "    data['education'] = pd.read_excel(xls, 'Education').fillna('').to_dict('records')\n",
        "    data['personal_projects'] = pd.read_excel(xls, 'Personal_Projects').fillna('').to_dict('records')\n",
        "\n",
        "    print(\"Data loaded and reconstructed.\")\n",
        "    return data\n",
        "\n",
        "def get_job_description():\n",
        "    return \"\"\"\n",
        "    About Us: TSMC IT Business AI team is dedicated to developing next-generation technologies...\n",
        "    Requirements:\n",
        "    * A minimum of a Master's degree in Computer Science, Artificial Intelligence...\n",
        "    * At least 3 years of experience in AI/Machine Learning. Strong proficiency in Python with a proven track record in AI/ML project development. Experience with Natural Language Processing (NLP) and Large Language Models (LLMs), as well as graph embedding techniques...\n",
        "    * Excellent communication and teamwork skills.\n",
        "    * Business domain knowledge in supply chain management is desirable.\n",
        "    \"\"\"\n"
      ],
      "metadata": {
        "id": "8KmzWwgPzxG3"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Agent Definitions ---\n",
        "recruiter_agent = autogen.ConversableAgent(\n",
        "    name=\"RecruiterAgent\",\n",
        "    system_message=\"\"\"You are a senior technical recruiter. Your task is to analyze a candidate's resume against a job description.\n",
        "            Think carefully about your response. Your entire response must be a JSON object inside a ```json code block.\n",
        "            Follow these steps exactly:\n",
        "            1.  Generate a single JSON object that conforms to the schema provided below.\n",
        "            2.  Place the opening JSON code block delimiter: ```json\n",
        "            3.  Paste the generated JSON object on the next line.\n",
        "            4.  Place the closing code block delimiter: ```\n",
        "            5.  Your response must contain **nothing** but this JSON code block. Do not add any conversational text or explanations before or after it.\n",
        "\n",
        "            JSON Schema:\n",
        "            {\n",
        "              \"candidate_name\": \"string\",\n",
        "              \"match_score\": \"integer\",\n",
        "              \"summary\": \"string\",\n",
        "              \"keyword_match\": { \"matched\": [\"string\"], \"missing\": [\"string\"] }\n",
        "            }\"\"\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "def is_json_termination_msg(message):\n",
        "    \"\"\"Checks if the message content contains a JSON code block.\"\"\"\n",
        "    content = message.get(\"content\", \"\")\n",
        "    print(f\"Checking message for termination: {content}\")\n",
        "    return \"```json\" in content\n",
        "\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"UserProxyAgent\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=is_json_termination_msg,  # Add the termination condition\n",
        "    max_consecutive_auto_reply=2,\n",
        ")\n"
      ],
      "metadata": {
        "id": "HiSpTP7Y37uo"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Agentic Workflow ---\n",
        "candidate_data = load_data_from_excel(\"resume_data.xlsx\")\n",
        "if candidate_data:\n",
        "    job_desc = get_job_description()\n",
        "    user_proxy.initiate_chat(\n",
        "        recruiter_agent,\n",
        "        message=f\"\"\"Please analyze the following candidate's resume data against the job description.\n",
        "            Job Description:\n",
        "            ---\n",
        "            {job_desc}\n",
        "            ---\n",
        "\n",
        "            Candidate's Resume Data (JSON):\n",
        "            ---\n",
        "            {json.dumps(candidate_data, indent=2)}\n",
        "            ---\n",
        "            \"\"\",\n",
        "    )\n",
        "\n",
        "    # --- Print Final Output ---\n",
        "    final_json_response = None\n",
        "    last_message = user_proxy.last_message(recruiter_agent)\n",
        "    if \"```json\" in last_message[\"content\"]:\n",
        "        final_json_response = last_message[\"content\"].split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "    if final_json_response:\n",
        "        print(\"\\n\" + \"=\"*20 + \" Candidate Ranking Analysis \" + \"=\"*20)\n",
        "        try:\n",
        "            analysis_data = json.loads(final_json_response)\n",
        "            print(json.dumps(analysis_data, indent=2))\n",
        "            print(\"\\nFinished. ATS workflow complete.\")\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error: Could not parse the JSON from the LLM's final response.\")\n",
        "    else:\n",
        "        print(\"\\nError: Could not find the final JSON analysis in the conversation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m2IXrSIC1v2",
        "outputId": "a8f85c52-0c2c-44c4-a74f-44e178f13c4f"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Loading structured data from 'resume_data.xlsx'...\n",
            "✅ Data loaded and reconstructed.\n",
            "UserProxyAgent (to RecruiterAgent):\n",
            "\n",
            "Please analyze the following candidate's resume data against the job description.\n",
            "            Job Description:\n",
            "            ---\n",
            "            \n",
            "    About Us: TSMC IT Business AI team is dedicated to developing next-generation technologies...\n",
            "    Requirements:\n",
            "    * A minimum of a Master's degree in Computer Science, Artificial Intelligence...\n",
            "    * At least 3 years of experience in AI/Machine Learning. Strong proficiency in Python with a proven track record in AI/ML project development. Experience with Natural Language Processing (NLP) and Large Language Models (LLMs), as well as graph embedding techniques...\n",
            "    * Excellent communication and teamwork skills.\n",
            "    * Business domain knowledge in supply chain management is desirable.\n",
            "    \n",
            "            ---\n",
            "\n",
            "            Candidate's Resume Data (JSON):\n",
            "            ---\n",
            "            {\n",
            "  \"contact_information\": {\n",
            "    \"name\": \"JIMMY LIU\",\n",
            "    \"email\": \"jimmyliu.ii12@nycu.edu.tw\",\n",
            "    \"phone\": \"+886 978768367\",\n",
            "    \"location\": \"Taiwan Taipei\",\n",
            "    \"links\": \"['Github: Jimmynyu']\"\n",
            "  },\n",
            "  \"professional_summary\": \"AI/ML engineer with specialized expertise in LLM quantization and foundation models. Seeking an opportunity to contribute to AI development, leveraging LLM optimization and deployment background.\",\n",
            "  \"skills\": [\n",
            "    \"Agent Coding\",\n",
            "    \"Python (Advanced)\",\n",
            "    \"PyTorch & TensorFlow\",\n",
            "    \"Git version control\",\n",
            "    \"LLM fine-tuning & deployment\",\n",
            "    \"Foundation model dev.\",\n",
            "    \"Deep learning optimization\",\n",
            "    \"Quantitative analysis\",\n",
            "    \"Linux administration\",\n",
            "    \"Verilog\",\n",
            "    \"Communication\",\n",
            "    \"English TOEIC 935\"\n",
            "  ],\n",
            "  \"work_experience\": [\n",
            "    {\n",
            "      \"job_title\": \"EDA Software Engineer\",\n",
            "      \"company\": \"MediaTek\",\n",
            "      \"location\": \"Hsinchu, Taiwan\",\n",
            "      \"responsibilities\": \"['Implemented and optimized LLM-based workflows, achieving 50% acceleration in processing speed.', 'Developed and maintained Python-based automation tools for workflow optimization.', 'Created comprehensive technical documentation and user guides for cross-team collaboration.', 'Utilized Git for version control and collaborative development.']\"\n",
            "    },\n",
            "    {\n",
            "      \"job_title\": \"Impedance Engineer\",\n",
            "      \"company\": \"Broadcom\",\n",
            "      \"location\": \"Hsinchu, Taiwan\",\n",
            "      \"responsibilities\": \"['Designed and implemented new automated workflow system using Python, reducing processing time by 70%.', 'Led technical documentation efforts and knowledge sharing initiatives across teams.', 'Collaborated with cross-functional teams to optimize design solutions.']\"\n",
            "    }\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"Master\\u2019s Degree\",\n",
            "      \"institution\": \"Institute of Artificial Intelligence Innovation, National Yang Ming Chiao Tung University\",\n",
            "      \"location\": \"Hsinchu, Taiwan\"\n",
            "    }\n",
            "  ],\n",
            "  \"personal_projects\": [\n",
            "    {\n",
            "      \"project_name\": \"Algorithmic Trading Agent for TSMC Stock Using Deep Reinforcement Learning\",\n",
            "      \"description\": \"Developed PPO agent with FinRL based on historical market data and technical indicators. Engineered a data pipeline on time series data and evaluate the agent\\u2019s strategy via a multi-year backtest, analyzing performance with metrics like Sharpe Ratio and Max Drawdown.\"\n",
            "    },\n",
            "    {\n",
            "      \"project_name\": \"YouTube Trend Analysis & NLP Application\",\n",
            "      \"description\": \"Developed system extracting/analyzing YouTube comments (YouTube Data API). Applied Hugging Face Transformers (sentiment) & TF-IDF (keywords).\"\n",
            "    },\n",
            "    {\n",
            "      \"project_name\": \"LLM-Powered Data Retrieval & Filtering\",\n",
            "      \"description\": \"Engineered LLM solution with function calls for targeted YouTube video search. Implemented regional/keyword-based trend filtering & automated comment data fetching.\"\n",
            "    },\n",
            "    {\n",
            "      \"project_name\": \"Multi-Agent AI Resume Parser & Analyzer\",\n",
            "      \"description\": \"Engineered LLM solution to extract information and save in excel format. Analyze the information in excel to output the summary of the resume.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "            ---\n",
            "            \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-09 19:54:42] {695} WARNING - Model llama3:instruct is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model llama3:instruct is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RecruiterAgent (to UserProxyAgent):\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"candidate_name\": \"JIMMY LIU\",\n",
            "  \"match_score\": 85,\n",
            "  \"summary\": \"The candidate has a strong background in AI/ML, with experience in LLM and NLP. They have a proven track record of developing AI projects and have excellent communication skills.\",\n",
            "  \"keyword_match\": {\n",
            "    \"matched\": [\n",
            "      \"Python\", \n",
            "      \"AI/Machine Learning\", \n",
            "      \"Natural Language Processing (NLP)\", \n",
            "      \"Large Language Models (LLMs)\", \n",
            "      \"graph embedding techniques\"\n",
            "    ],\n",
            "    \"missing\": [\n",
            "      \"Master's degree in Computer Science, Artificial Intelligence\", \n",
            "      \"At least 3 years of experience in AI/Machine Learning\", \n",
            "      \"Business domain knowledge in supply chain management\"\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Checking message for termination: ```json\n",
            "{\n",
            "  \"candidate_name\": \"JIMMY LIU\",\n",
            "  \"match_score\": 85,\n",
            "  \"summary\": \"The candidate has a strong background in AI/ML, with experience in LLM and NLP. They have a proven track record of developing AI projects and have excellent communication skills.\",\n",
            "  \"keyword_match\": {\n",
            "    \"matched\": [\n",
            "      \"Python\", \n",
            "      \"AI/Machine Learning\", \n",
            "      \"Natural Language Processing (NLP)\", \n",
            "      \"Large Language Models (LLMs)\", \n",
            "      \"graph embedding techniques\"\n",
            "    ],\n",
            "    \"missing\": [\n",
            "      \"Master's degree in Computer Science, Artificial Intelligence\", \n",
            "      \"At least 3 years of experience in AI/Machine Learning\", \n",
            "      \"Business domain knowledge in supply chain management\"\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (358c6716-9a3f-4585-93f7-02f40a453967): Termination message condition on agent 'UserProxyAgent' met\n",
            "\n",
            "==================== Candidate Ranking Analysis ====================\n",
            "{\n",
            "  \"candidate_name\": \"JIMMY LIU\",\n",
            "  \"match_score\": 85,\n",
            "  \"summary\": \"The candidate has a strong background in AI/ML, with experience in LLM and NLP. They have a proven track record of developing AI projects and have excellent communication skills.\",\n",
            "  \"keyword_match\": {\n",
            "    \"matched\": [\n",
            "      \"Python\",\n",
            "      \"AI/Machine Learning\",\n",
            "      \"Natural Language Processing (NLP)\",\n",
            "      \"Large Language Models (LLMs)\",\n",
            "      \"graph embedding techniques\"\n",
            "    ],\n",
            "    \"missing\": [\n",
            "      \"Master's degree in Computer Science, Artificial Intelligence\",\n",
            "      \"At least 3 years of experience in AI/Machine Learning\",\n",
            "      \"Business domain knowledge in supply chain management\"\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\n",
            "🎉 Part 2 Finished. ATS workflow complete.\n"
          ]
        }
      ]
    }
  ]
}