{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPrW/LfRDe4WDFvCduJoIO7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jimmynycu/ATS_with_gemini_api/blob/main/Applicant_Tracking_System_with_ollama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyautogen pypdf pandas openpyxl python-dotenv autogen --quiet\n",
        "\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSVhgfaEUdd7",
        "outputId": "553728ba-9e74-43da-eeb3-0c7c0e67e195"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/310.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m834.0/834.0 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.1/119.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h>>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import autogen\n",
        "import json\n",
        "import pandas as pd\n",
        "from pypdf import PdfReader\n",
        "import os\n",
        "import asyncio"
      ],
      "metadata": {
        "id": "g5SHdREyVU90"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pid = os.fork()\n",
        "if pid == 0:\n",
        "    os.execv('/usr/local/bin/ollama', ['ollama', 'serve'])\n",
        "else:\n",
        "    print(\"Ollama server started in the background.\")\n",
        "\n",
        "await asyncio.sleep(5)\n",
        "!ollama pull llama3:instruct &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF-F50eSUjwP",
        "outputId": "9477c304-3c98-4129-8542-5c240462b06d"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1792677764.py:1: DeprecationWarning: This process (pid=1140) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ollama server started in the background.\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbc3c5c8",
        "outputId": "3dd1eb3a-5991-4b4e-c3cd-4d8fc3f3fd12"
      },
      "source": [
        "import httpx\n",
        "import json # Import json to potentially print the response data\n",
        "\n",
        "ollama_chat_url = \"http://127.0.0.1:11434/api/chat\"\n",
        "model_name = \"llama3:instruct\"\n",
        "prompt_message = {\"role\": \"user\", \"content\": \"Are you ready?\"}\n",
        "payload = {\n",
        "    \"model\": model_name,\n",
        "    \"messages\": [prompt_message],\n",
        "    \"stream\": False\n",
        "}\n",
        "\n",
        "print(f\"Sending simple test prompt to {ollama_chat_url}...\")\n",
        "\n",
        "# Send the POST request\n",
        "response = httpx.post(ollama_chat_url, json=payload, timeout=10.0) # Added a basic timeout\n",
        "\n",
        "# Print the status code and response text/json\n",
        "print(f\"Response Status Code: {response.status_code}\")\n",
        "try:\n",
        "    # Attempt to parse and print JSON if possible\n",
        "    print(\"Response Body (JSON if available):\")\n",
        "    print(json.dumps(response.json(), indent=2))\n",
        "except json.JSONDecodeError:\n",
        "    # Otherwise, print raw text\n",
        "    print(\"Response Body (Text):\")\n",
        "    print(response.text)\n",
        "\n",
        "print(\"\\nSimple test complete.\")"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sending simple test prompt to http://127.0.0.1:11434/api/chat...\n",
            "Response Status Code: 200\n",
            "Response Body (JSON if available):\n",
            "{\n",
            "  \"model\": \"llama3:instruct\",\n",
            "  \"created_at\": \"2025-09-09T19:48:09.853287692Z\",\n",
            "  \"message\": {\n",
            "    \"role\": \"assistant\",\n",
            "    \"content\": \"I'm always ready! What's next?\"\n",
            "  },\n",
            "  \"done_reason\": \"stop\",\n",
            "  \"done\": true,\n",
            "  \"total_duration\": 3172958254,\n",
            "  \"load_duration\": 2702521389,\n",
            "  \"prompt_eval_count\": 14,\n",
            "  \"prompt_eval_duration\": 151055268,\n",
            "  \"eval_count\": 10,\n",
            "  \"eval_duration\": 318451398\n",
            "}\n",
            "\n",
            "Simple test complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_list=[\n",
        "    {\n",
        "        \"model\": \"llama3:instruct\",\n",
        "        \"base_url\": \"http://127.0.0.1:11434/v1\",\n",
        "        \"api_key\": \"ollama\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "wNCOVhUDUywl"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "llm_config = {\n",
        "        \"config_list\": config_list,\n",
        "        \"temperature\": 0.0\n",
        "        }"
      ],
      "metadata": {
        "id": "s5ya_ZljU3gN"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser_agent = autogen.ConversableAgent(\n",
        "    name=\"ResumeParserAgent\",\n",
        "    system_message=\"\"\"You are an expert HR data extraction specialist.\n",
        "            Your ONLY task is to parse resume text into a structured JSON format. You must STRICTLY and LITERALLY adhere to the following rules:\n",
        "            1.  Begin your response with a ```json code block.\n",
        "            2.  Provide the complete, raw JSON object inside the code block.\n",
        "            3.  End your response with the closing ``` code block.\n",
        "            4.  Your entire response must consist of NOTHING but the JSON object enclosed within the opening and closing ```json``` code blocks.\n",
        "            5.  DO NOT add any other text, commentary, greetings, or explanations before, after, or inside the code block.\n",
        "            \"\"\",\n",
        "            llm_config=llm_config,\n",
        "            human_input_mode=\"NEVER\",\n",
        "    )\n",
        "\n",
        "# Function to check for the termination condition\n",
        "def is_json_termination_msg(message):\n",
        "    content = message.get(\"content\", \"\")\n",
        "    print(f\"Checking message for termination: {content}\")\n",
        "    # This checks for a code block that starts with \"```json\" and ends with \"```\".\n",
        "    return content.startswith(\"```json\") and content.endswith(\"```\")\n",
        "\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"UserProxyAgent\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False},\n",
        "    is_termination_msg=is_json_termination_msg,\n",
        "    max_consecutive_auto_reply=10,\n",
        ")"
      ],
      "metadata": {
        "id": "yg6ALLuYY6p8"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF\n",
        "pdf_path = \"Jimmy_CV.pdf\"\n",
        "raw_resume_text = \"\"\n",
        "try:\n",
        "    reader = PdfReader(pdf_path)\n",
        "    for page in reader.pages:\n",
        "        raw_resume_text += page.extract_text() or \"\"\n",
        "    print(\"PDF text extracted successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{pdf_path}' not found.\")\n",
        "else:\n",
        "    # --- Agentic Workflow ---\n",
        "    user_proxy.initiate_chat(\n",
        "        parser_agent,\n",
        "        message=f\"\"\"\n",
        "            Please parse the following resume text into the required JSON format.\n",
        "\n",
        "            JSON Schema:\n",
        "            {{\n",
        "              \"contact_information\": {{ \"name\": \"string\", \"email\": \"string\", \"phone\": \"string\", \"location\": \"string\", \"links\": [\"string\"] }},\n",
        "              \"professional_summary\": \"string\",\n",
        "              \"skills\": [\"string\"],\n",
        "              \"work_experience\": [ {{ \"job_title\": \"string\", \"company\": \"string\", \"location\": \"string\", \"responsibilities\": [\"string\"] }} ],\n",
        "              \"education\": [ {{ \"degree\": \"string\", \"institution\": \"string\", \"location\": \"string\" }} ],\n",
        "              \"personal_projects\": [ {{ \"project_name\": \"string\", \"description\": \"string\" }} ]\n",
        "            }}\n",
        "\n",
        "            Resume Text:\n",
        "            ---\n",
        "            {raw_resume_text}\n",
        "            ---\n",
        "            \"\"\",\n",
        "    )\n",
        "\n",
        "    # --- Save Output ---\n",
        "    json_string = None\n",
        "    last_message = user_proxy.last_message(parser_agent)\n",
        "\n",
        "    if last_message and \"```json\" in last_message[\"content\"]:\n",
        "        json_string = last_message[\"content\"].split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "    if json_string:\n",
        "        print(\"\\n LLM generated the structured JSON. Now saving to Excel...\")\n",
        "        try:\n",
        "            data = json.loads(json_string)\n",
        "            with pd.ExcelWriter(\"resume_data.xlsx\", engine='openpyxl') as writer:\n",
        "\n",
        "                # 1. Save Contact Information\n",
        "                contact_info_df = pd.DataFrame([data.get('contact_information', {})])\n",
        "                contact_info_df.to_excel(writer, sheet_name='Contact_Info', index=False)\n",
        "\n",
        "                # 2. Save Professional Summary\n",
        "                professional_summary_df = pd.DataFrame({'summary': [data.get('professional_summary', '')]})\n",
        "                professional_summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "                # 3. Save Skills\n",
        "                skills_list = data.get('skills', [])\n",
        "                skills_df = pd.DataFrame(skills_list, columns=['Skill'])\n",
        "                skills_df.to_excel(writer, sheet_name='Skills', index=False)\n",
        "\n",
        "                # 4. Save Work Experience\n",
        "                work_experience_list = data.get('work_experience', [])\n",
        "                work_experience_df = pd.DataFrame(work_experience_list)\n",
        "                work_experience_df.to_excel(writer, sheet_name='Work_Experience', index=False)\n",
        "\n",
        "                # 5. Save Education\n",
        "                education_list = data.get('education', [])\n",
        "                education_df = pd.DataFrame(education_list)\n",
        "                education_df.to_excel(writer, sheet_name='Education', index=False)\n",
        "\n",
        "                # 6. Save Personal Projects\n",
        "                personal_projects_list = data.get('personal_projects', [])\n",
        "                personal_projects_df = pd.DataFrame(personal_projects_list)\n",
        "                personal_projects_df.to_excel(writer, sheet_name='Personal_Projects', index=False)\n",
        "\n",
        "            print(\"Excel file 'resume_data.xlsx' saved successfully. You can find it in the file browser.\")\n",
        "\n",
        "        except (json.JSONDecodeError, KeyError) as e:\n",
        "            print(f\"Error: Could not process the JSON from the LLM. Error: {e}\")\n",
        "    else:\n",
        "        print(\"\\nError: Could not find the JSON output from the LLM conversation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jYImht6Y9Yn",
        "outputId": "9aae3417-c246-4109-e2c4-ecf002d6e723"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF text extracted successfully.\n",
            "UserProxyAgent (to ResumeParserAgent):\n",
            "\n",
            "\n",
            "            Please parse the following resume text into the required JSON format.\n",
            "\n",
            "            JSON Schema:\n",
            "            {\n",
            "              \"contact_information\": { \"name\": \"string\", \"email\": \"string\", \"phone\": \"string\", \"location\": \"string\", \"links\": [\"string\"] },\n",
            "              \"professional_summary\": \"string\",\n",
            "              \"skills\": [\"string\"],\n",
            "              \"work_experience\": [ { \"job_title\": \"string\", \"company\": \"string\", \"location\": \"string\", \"responsibilities\": [\"string\"] } ],\n",
            "              \"education\": [ { \"degree\": \"string\", \"institution\": \"string\", \"location\": \"string\" } ],\n",
            "              \"personal_projects\": [ { \"project_name\": \"string\", \"description\": \"string\" } ]\n",
            "            }\n",
            "\n",
            "            Resume Text:\n",
            "            ---\n",
            "            JIMMY LIU\n",
            "Taiwan Taipeiâ‹„ +886 978768367 â‹„ jimmyliu.ii12@nycu.edu.tw â‹„ Github: Jimmynyu\n",
            "PROFESSIONAL SUMMARY\n",
            "AI/ML engineer with specialized expertise in LLM quantization and foundation models. Seeking an opportunity to\n",
            "contribute to AI development, leveraging LLM optimization and deployment background.\n",
            "SKILLS\n",
            "Programming Languages:\n",
            "â€¢ Agent Coding\n",
            "â€¢ Python (Advanced)\n",
            "â€¢ PyTorch & TensorFlow\n",
            "â€¢ Git version control\n",
            "AI/ML Expertise:\n",
            "â€¢ LLM fine-tuning & deployment\n",
            "â€¢ Foundation model dev.\n",
            "â€¢ Deep learning optimization\n",
            "â€¢ Quantitative analysis\n",
            "Additional Technical Skills:\n",
            "â€¢ Linux administration\n",
            "â€¢ Verilog\n",
            "â€¢ Communication\n",
            "â€¢ English TOEIC 935\n",
            "EXPERIENCE\n",
            "EDA Software Engineer\n",
            "MediaTek â€“ Hsinchu, Taiwan\n",
            "â€¢ Implemented and optimized LLM-based workflows, achieving 50% acceleration in processing speed.\n",
            "â€¢ Developed and maintained Python-based automation tools for workflow optimization.\n",
            "â€¢ Created comprehensive technical documentation and user guides for cross-team collaboration.\n",
            "â€¢ Utilized Git for version control and collaborative development.\n",
            "Impedance Engineer\n",
            "Broadcom â€“ Hsinchu, Taiwan\n",
            "â€¢ Designed and implemented new automated workflow system using Python, reducing processing time by 70%.\n",
            "â€¢ Led technical documentation efforts and knowledge sharing initiatives across teams.\n",
            "â€¢ Collaborated with cross-functional teams to optimize design solutions.\n",
            "EDUCATION\n",
            "Masterâ€™s Degree: Institute of Artificial Intelligence Innovation\n",
            "National Yang Ming Chiao Tung Universityâ€“ Hsinchu, Taiwan\n",
            "â€¢ Focusing on LLM calibration; coursework in machine learning & deep learning fundamentals.\n",
            "â€¢ Experience in LLM fine-tuning, Retrieval Augmented Generation (RAG), and test bench.\n",
            "â€¢ Designed software simulations of AI models to guide hardware acceleration development.\n",
            "PERSONAL PROJECTS\n",
            "â€¢ Algorithmic Trading Agent for TSMC Stock Using Deep Reinforcement Learning\n",
            "â€“ Developed PPO agent withFinRL based on historical market data and technical indicators.\n",
            "â€“ Engineered a data pipelineon time series data and evaluate the agentâ€™s strategy via a multi-year backtest,\n",
            "analyzing performance with metrics likeSharpe Ratioand Max Drawdown.\n",
            "â€¢ YouTube Trend Analysis & NLP Application:\n",
            "â€“ Developed system extracting/analyzing YouTube comments (YouTube Data API).\n",
            "â€“ Applied Hugging Face Transformers (sentiment) & TF-IDF (keywords).\n",
            "â€¢ LLM-Powered Data Retrieval & Filtering:\n",
            "â€“ Engineered LLM solution with function calls for targeted YouTube video search.\n",
            "â€“ Implemented regional/keyword-based trend filtering & automated comment data fetching.\n",
            "â€¢ Multi-Agent AI Resume Parser & Analyzer:\n",
            "â€“ Engineered LLM solution to extract information and save in excel format.\n",
            "â€“ Analyze the information in excel to output the summary of the resume.\n",
            "            ---\n",
            "            \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-09 19:26:03] {695} WARNING - Model llama3:instruct is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model llama3:instruct is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResumeParserAgent (to UserProxyAgent):\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"contact_information\": {\n",
            "    \"name\": \"JIMMY LIU\",\n",
            "    \"email\": \"jimmyliu.ii12@nycu.edu.tw\",\n",
            "    \"phone\": \"+886 978768367\",\n",
            "    \"location\": \"Taiwan Taipei\",\n",
            "    \"links\": [\"Github: Jimmynyu\"]\n",
            "  },\n",
            "  \"professional_summary\": \"AI/ML engineer with specialized expertise in LLM quantization and foundation models. Seeking an opportunity to contribute to AI development, leveraging LLM optimization and deployment background.\",\n",
            "  \"skills\": [\n",
            "    \"Agent Coding\",\n",
            "    \"Python (Advanced)\",\n",
            "    \"PyTorch & TensorFlow\",\n",
            "    \"Git version control\",\n",
            "    \"LLM fine-tuning & deployment\",\n",
            "    \"Foundation model dev.\",\n",
            "    \"Deep learning optimization\",\n",
            "    \"Quantitative analysis\",\n",
            "    \"Linux administration\",\n",
            "    \"Verilog\",\n",
            "    \"Communication\",\n",
            "    \"English TOEIC 935\"\n",
            "  ],\n",
            "  \"work_experience\": [\n",
            "    {\n",
            "      \"job_title\": \"EDA Software Engineer\",\n",
            "      \"company\": \"MediaTek\",\n",
            "      \"location\": \"Hsinchu, Taiwan\",\n",
            "      \"responsibilities\": [\n",
            "        \"Implemented and optimized LLM-based workflows, achieving 50% acceleration in processing speed.\",\n",
            "        \"Developed and maintained Python-based automation tools for workflow optimization.\",\n",
            "        \"Created comprehensive technical documentation and user guides for cross-team collaboration.\",\n",
            "        \"Utilized Git for version control and collaborative development.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"job_title\": \"Impedance Engineer\",\n",
            "      \"company\": \"Broadcom\",\n",
            "      \"location\": \"Hsinchu, Taiwan\",\n",
            "      \"responsibilities\": [\n",
            "        \"Designed and implemented new automated workflow system using Python, reducing processing time by 70%.\",\n",
            "        \"Led technical documentation efforts and knowledge sharing initiatives across teams.\",\n",
            "        \"Collaborated with cross-functional teams to optimize design solutions.\"\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"Masterâ€™s Degree\",\n",
            "      \"institution\": \"Institute of Artificial Intelligence Innovation, National Yang Ming Chiao Tung University\",\n",
            "      \"location\": \"Hsinchu, Taiwan\"\n",
            "    }\n",
            "  ],\n",
            "  \"personal_projects\": [\n",
            "    {\n",
            "      \"project_name\": \"Algorithmic Trading Agent for TSMC Stock Using Deep Reinforcement Learning\",\n",
            "      \"description\": \"Developed PPO agent with FinRL based on historical market data and technical indicators. Engineered a data pipeline on time series data and evaluate the agentâ€™s strategy via a multi-year backtest, analyzing performance with metrics like Sharpe Ratio and Max Drawdown.\"\n",
            "    },\n",
            "    {\n",
            "      \"project_name\": \"YouTube Trend Analysis & NLP Application\",\n",
            "      \"description\": \"Developed system extracting/analyzing YouTube comments (YouTube Data API). Applied Hugging Face Transformers (sentiment) & TF-IDF (keywords).\"\n",
            "    },\n",
            "    {\n",
            "      \"project_name\": \"LLM-Powered Data Retrieval & Filtering\",\n",
            "      \"description\": \"Engineered LLM solution with function calls for targeted YouTube video search. Implemented regional/keyword-based trend filtering & automated comment data fetching.\"\n",
            "    },\n",
            "    {\n",
            "      \"project_name\": \"Multi-Agent AI Resume Parser & Analyzer\",\n",
            "      \"description\": \"Engineered LLM solution to extract information and save in excel format. Analyze the information in excel to output the summary of the resume.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (904011c5-8640-4576-856d-33471de646bf): Termination message condition on agent 'UserProxyAgent' met\n",
            "\n",
            "âœ… LLM generated the structured JSON. Now saving to Excel...\n",
            "ðŸ’¾ Excel file 'resume_data.xlsx' saved successfully. You can find it in the file browser.\n",
            "\n",
            "ðŸŽ‰ Part 1 Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_from_excel(file_path: str):\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Error: The file '{file_path}' was not found.\")\n",
        "        return None\n",
        "    print(f\" Loading structured data from '{file_path}'...\")\n",
        "    xls = pd.ExcelFile(file_path)\n",
        "    data = {}\n",
        "    data['contact_information'] = pd.read_excel(xls, 'Contact_Info').fillna('').to_dict('records')[0]\n",
        "    data['professional_summary'] = pd.read_excel(xls, 'Summary').fillna('').to_dict('records')[0]['summary']\n",
        "    data['skills'] = pd.read_excel(xls, 'Skills')['Skill'].dropna().tolist()\n",
        "    data['work_experience'] = pd.read_excel(xls, 'Work_Experience').fillna('').to_dict('records')\n",
        "    data['education'] = pd.read_excel(xls, 'Education').fillna('').to_dict('records')\n",
        "    data['personal_projects'] = pd.read_excel(xls, 'Personal_Projects').fillna('').to_dict('records')\n",
        "\n",
        "    print(\"Data loaded and reconstructed.\")\n",
        "    return data\n",
        "\n",
        "def get_job_description():\n",
        "    return \"\"\"\n",
        "    About Us: TSMC IT Business AI team is dedicated to developing next-generation technologies...\n",
        "    Requirements:\n",
        "    * A minimum of a Master's degree in Computer Science, Artificial Intelligence...\n",
        "    * At least 3 years of experience in AI/Machine Learning. Strong proficiency in Python with a proven track record in AI/ML project development. Experience with Natural Language Processing (NLP) and Large Language Models (LLMs), as well as graph embedding techniques...\n",
        "    * Excellent communication and teamwork skills.\n",
        "    * Business domain knowledge in supply chain management is desirable.\n",
        "    \"\"\"\n"
      ],
      "metadata": {
        "id": "8KmzWwgPzxG3"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Agent Definitions ---\n",
        "recruiter_agent = autogen.ConversableAgent(\n",
        "    name=\"RecruiterAgent\",\n",
        "    system_message=\"\"\"You are a senior technical recruiter. Your task is to analyze a candidate's resume against a job description.\n",
        "            Think carefully about your response. Your entire response must be a JSON object inside a ```json code block.\n",
        "            Follow these steps exactly:\n",
        "            1.  Generate a single JSON object that conforms to the schema provided below.\n",
        "            2.  Place the opening JSON code block delimiter: ```json\n",
        "            3.  Paste the generated JSON object on the next line.\n",
        "            4.  Place the closing code block delimiter: ```\n",
        "            5.  Your response must contain **nothing** but this JSON code block. Do not add any conversational text or explanations before or after it.\n",
        "\n",
        "            JSON Schema:\n",
        "            {\n",
        "              \"candidate_name\": \"string\",\n",
        "              \"match_score\": \"integer\",\n",
        "              \"summary\": \"string\",\n",
        "              \"keyword_match\": { \"matched\": [\"string\"], \"missing\": [\"string\"] }\n",
        "            }\"\"\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "def is_json_termination_msg(message):\n",
        "    \"\"\"Checks if the message content contains a JSON code block.\"\"\"\n",
        "    content = message.get(\"content\", \"\")\n",
        "    print(f\"Checking message for termination: {content}\")\n",
        "    return \"```json\" in content\n",
        "\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"UserProxyAgent\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=is_json_termination_msg,  # Add the termination condition\n",
        "    max_consecutive_auto_reply=2,\n",
        ")\n"
      ],
      "metadata": {
        "id": "HiSpTP7Y37uo"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Agentic Workflow ---\n",
        "candidate_data = load_data_from_excel(\"resume_data.xlsx\")\n",
        "if candidate_data:\n",
        "    job_desc = get_job_description()\n",
        "    user_proxy.initiate_chat(\n",
        "        recruiter_agent,\n",
        "        message=f\"\"\"Please analyze the following candidate's resume data against the job description.\n",
        "            Job Description:\n",
        "            ---\n",
        "            {job_desc}\n",
        "            ---\n",
        "\n",
        "            Candidate's Resume Data (JSON):\n",
        "            ---\n",
        "            {json.dumps(candidate_data, indent=2)}\n",
        "            ---\n",
        "            \"\"\",\n",
        "    )\n",
        "\n",
        "    # --- Print Final Output ---\n",
        "    final_json_response = None\n",
        "    last_message = user_proxy.last_message(recruiter_agent)\n",
        "    if \"```json\" in last_message[\"content\"]:\n",
        "        final_json_response = last_message[\"content\"].split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "    if final_json_response:\n",
        "        print(\"\\n\" + \"=\"*20 + \" Candidate Ranking Analysis \" + \"=\"*20)\n",
        "        try:\n",
        "            analysis_data = json.loads(final_json_response)\n",
        "            print(json.dumps(analysis_data, indent=2))\n",
        "            print(\"\\nFinished. ATS workflow complete.\")\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Error: Could not parse the JSON from the LLM's final response.\")\n",
        "    else:\n",
        "        print(\"\\nError: Could not find the final JSON analysis in the conversation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m2IXrSIC1v2",
        "outputId": "a8f85c52-0c2c-44c4-a74f-44e178f13c4f"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Loading structured data from 'resume_data.xlsx'...\n",
            "âœ… Data loaded and reconstructed.\n",
            "UserProxyAgent (to RecruiterAgent):\n",
            "\n",
            "Please analyze the following candidate's resume data against the job description.\n",
            "            Job Description:\n",
            "            ---\n",
            "            \n",
            "    About Us: TSMC IT Business AI team is dedicated to developing next-generation technologies...\n",
            "    Requirements:\n",
            "    * A minimum of a Master's degree in Computer Science, Artificial Intelligence...\n",
            "    * At least 3 years of experience in AI/Machine Learning. Strong proficiency in Python with a proven track record in AI/ML project development. Experience with Natural Language Processing (NLP) and Large Language Models (LLMs), as well as graph embedding techniques...\n",
            "    * Excellent communication and teamwork skills.\n",
            "    * Business domain knowledge in supply chain management is desirable.\n",
            "    \n",
            "            ---\n",
            "\n",
            "            Candidate's Resume Data (JSON):\n",
            "            ---\n",
            "            {\n",
            "  \"contact_information\": {\n",
            "    \"name\": \"JIMMY LIU\",\n",
            "    \"email\": \"jimmyliu.ii12@nycu.edu.tw\",\n",
            "    \"phone\": \"+886 978768367\",\n",
            "    \"location\": \"Taiwan Taipei\",\n",
            "    \"links\": \"['Github: Jimmynyu']\"\n",
            "  },\n",
            "  \"professional_summary\": \"AI/ML engineer with specialized expertise in LLM quantization and foundation models. Seeking an opportunity to contribute to AI development, leveraging LLM optimization and deployment background.\",\n",
            "  \"skills\": [\n",
            "    \"Agent Coding\",\n",
            "    \"Python (Advanced)\",\n",
            "    \"PyTorch & TensorFlow\",\n",
            "    \"Git version control\",\n",
            "    \"LLM fine-tuning & deployment\",\n",
            "    \"Foundation model dev.\",\n",
            "    \"Deep learning optimization\",\n",
            "    \"Quantitative analysis\",\n",
            "    \"Linux administration\",\n",
            "    \"Verilog\",\n",
            "    \"Communication\",\n",
            "    \"English TOEIC 935\"\n",
            "  ],\n",
            "  \"work_experience\": [\n",
            "    {\n",
            "      \"job_title\": \"EDA Software Engineer\",\n",
            "      \"company\": \"MediaTek\",\n",
            "      \"location\": \"Hsinchu, Taiwan\",\n",
            "      \"responsibilities\": \"['Implemented and optimized LLM-based workflows, achieving 50% acceleration in processing speed.', 'Developed and maintained Python-based automation tools for workflow optimization.', 'Created comprehensive technical documentation and user guides for cross-team collaboration.', 'Utilized Git for version control and collaborative development.']\"\n",
            "    },\n",
            "    {\n",
            "      \"job_title\": \"Impedance Engineer\",\n",
            "      \"company\": \"Broadcom\",\n",
            "      \"location\": \"Hsinchu, Taiwan\",\n",
            "      \"responsibilities\": \"['Designed and implemented new automated workflow system using Python, reducing processing time by 70%.', 'Led technical documentation efforts and knowledge sharing initiatives across teams.', 'Collaborated with cross-functional teams to optimize design solutions.']\"\n",
            "    }\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"Master\\u2019s Degree\",\n",
            "      \"institution\": \"Institute of Artificial Intelligence Innovation, National Yang Ming Chiao Tung University\",\n",
            "      \"location\": \"Hsinchu, Taiwan\"\n",
            "    }\n",
            "  ],\n",
            "  \"personal_projects\": [\n",
            "    {\n",
            "      \"project_name\": \"Algorithmic Trading Agent for TSMC Stock Using Deep Reinforcement Learning\",\n",
            "      \"description\": \"Developed PPO agent with FinRL based on historical market data and technical indicators. Engineered a data pipeline on time series data and evaluate the agent\\u2019s strategy via a multi-year backtest, analyzing performance with metrics like Sharpe Ratio and Max Drawdown.\"\n",
            "    },\n",
            "    {\n",
            "      \"project_name\": \"YouTube Trend Analysis & NLP Application\",\n",
            "      \"description\": \"Developed system extracting/analyzing YouTube comments (YouTube Data API). Applied Hugging Face Transformers (sentiment) & TF-IDF (keywords).\"\n",
            "    },\n",
            "    {\n",
            "      \"project_name\": \"LLM-Powered Data Retrieval & Filtering\",\n",
            "      \"description\": \"Engineered LLM solution with function calls for targeted YouTube video search. Implemented regional/keyword-based trend filtering & automated comment data fetching.\"\n",
            "    },\n",
            "    {\n",
            "      \"project_name\": \"Multi-Agent AI Resume Parser & Analyzer\",\n",
            "      \"description\": \"Engineered LLM solution to extract information and save in excel format. Analyze the information in excel to output the summary of the resume.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "            ---\n",
            "            \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-09 19:54:42] {695} WARNING - Model llama3:instruct is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:Model llama3:instruct is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RecruiterAgent (to UserProxyAgent):\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"candidate_name\": \"JIMMY LIU\",\n",
            "  \"match_score\": 85,\n",
            "  \"summary\": \"The candidate has a strong background in AI/ML, with experience in LLM and NLP. They have a proven track record of developing AI projects and have excellent communication skills.\",\n",
            "  \"keyword_match\": {\n",
            "    \"matched\": [\n",
            "      \"Python\", \n",
            "      \"AI/Machine Learning\", \n",
            "      \"Natural Language Processing (NLP)\", \n",
            "      \"Large Language Models (LLMs)\", \n",
            "      \"graph embedding techniques\"\n",
            "    ],\n",
            "    \"missing\": [\n",
            "      \"Master's degree in Computer Science, Artificial Intelligence\", \n",
            "      \"At least 3 years of experience in AI/Machine Learning\", \n",
            "      \"Business domain knowledge in supply chain management\"\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Checking message for termination: ```json\n",
            "{\n",
            "  \"candidate_name\": \"JIMMY LIU\",\n",
            "  \"match_score\": 85,\n",
            "  \"summary\": \"The candidate has a strong background in AI/ML, with experience in LLM and NLP. They have a proven track record of developing AI projects and have excellent communication skills.\",\n",
            "  \"keyword_match\": {\n",
            "    \"matched\": [\n",
            "      \"Python\", \n",
            "      \"AI/Machine Learning\", \n",
            "      \"Natural Language Processing (NLP)\", \n",
            "      \"Large Language Models (LLMs)\", \n",
            "      \"graph embedding techniques\"\n",
            "    ],\n",
            "    \"missing\": [\n",
            "      \"Master's degree in Computer Science, Artificial Intelligence\", \n",
            "      \"At least 3 years of experience in AI/Machine Learning\", \n",
            "      \"Business domain knowledge in supply chain management\"\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (358c6716-9a3f-4585-93f7-02f40a453967): Termination message condition on agent 'UserProxyAgent' met\n",
            "\n",
            "==================== Candidate Ranking Analysis ====================\n",
            "{\n",
            "  \"candidate_name\": \"JIMMY LIU\",\n",
            "  \"match_score\": 85,\n",
            "  \"summary\": \"The candidate has a strong background in AI/ML, with experience in LLM and NLP. They have a proven track record of developing AI projects and have excellent communication skills.\",\n",
            "  \"keyword_match\": {\n",
            "    \"matched\": [\n",
            "      \"Python\",\n",
            "      \"AI/Machine Learning\",\n",
            "      \"Natural Language Processing (NLP)\",\n",
            "      \"Large Language Models (LLMs)\",\n",
            "      \"graph embedding techniques\"\n",
            "    ],\n",
            "    \"missing\": [\n",
            "      \"Master's degree in Computer Science, Artificial Intelligence\",\n",
            "      \"At least 3 years of experience in AI/Machine Learning\",\n",
            "      \"Business domain knowledge in supply chain management\"\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\n",
            "ðŸŽ‰ Part 2 Finished. ATS workflow complete.\n"
          ]
        }
      ]
    }
  ]
}