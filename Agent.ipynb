{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxJMzR7BhiS5rI8z3xKPvC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jimmynycu/ATS_with_gemini_api/blob/main/Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wlt59xQoYr5W"
      },
      "outputs": [],
      "source": [
        "# Install all required libraries for the project\n",
        "!pip install pyautogen pymupdf pandas xlsxwriter python-dotenv unidecode autogen -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import google.generativeai as genai # Import the genai library\n",
        "\n",
        "# Set your Google Gemini API key\n",
        "api_key = \"*******************\" # Replace with your actual key\n",
        "\n",
        "try:\n",
        "    # Configure the genai client with the API key\n",
        "    genai.configure(api_key=api_key)\n",
        "\n",
        "    # Make a simple, no-cost call to list the available models\n",
        "    models = genai.list_models()\n",
        "\n",
        "    # Check if a common model is in the list to confirm it's working\n",
        "    if any('gemini-1.5-flash' in m.name for m in models):\n",
        "        print(\"✅ API Key is valid and working.\")\n",
        "    else:\n",
        "        print(\"⚠️ API Key is valid, but the expected models were not found. Please check your key's permissions.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ API Key is NOT valid. Error: {e}\")\n",
        "    api_key = None # Set key to None to prevent further errors\n",
        "\n",
        "# --- Create Configuration File if Key is Valid ---\n",
        "if api_key:\n",
        "    # Define the configuration for AutoGen to use the Gemini model\n",
        "    config_list = [\n",
        "        {\n",
        "            \"model\": \"gemini-1.5-pro-latest\", # Using a robust and common model\n",
        "            \"api_key\": api_key,\n",
        "            \"api_type\": \"google\",\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Create the OAI_CONFIG_LIST.json file\n",
        "    # AutoGen uses this file to configure the LLM for the agents\n",
        "    with open(\"OAI_CONFIG_LIST.json\", \"w\") as f:\n",
        "        json.dump(config_list, f)\n",
        "\n",
        "    print(\"Configuration file for Gemini created successfully.\")\n",
        "else:\n",
        "    print(\"Configuration file was not created due to an invalid API key.\")"
      ],
      "metadata": {
        "id": "ugHDn_MFZ5ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "from unidecode import unidecode\n",
        "\n",
        "def parse_resume_with_pymupdf(pdf_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extracts structured text from a PDF resume using PyMuPDF.\n",
        "    This function reads a PDF file and extracts text in a structured manner,\n",
        "    preserving the reading order by processing text blocks.\n",
        "    \"\"\"\n",
        "    full_text = \"\"\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "        for page_num in range(len(doc)):\n",
        "            page = doc.load_page(page_num)\n",
        "\n",
        "            # The \"blocks\" option is crucial for maintaining reading order\n",
        "            blocks = page.get_text(\"blocks\")\n",
        "            blocks.sort(key=lambda b: (b[3], b))  # Sort by top, then left coordinate\n",
        "\n",
        "            page_text = []\n",
        "            for b in blocks:\n",
        "                # b[4] contains the text of the block\n",
        "                block_text = b[4]\n",
        "                # Clean text: remove leading/trailing whitespace and handle unicode\n",
        "                cleaned_text = unidecode(block_text.strip())\n",
        "                page_text.append(cleaned_text)\n",
        "\n",
        "            full_text += \"\\n\".join(page_text)\n",
        "            if page_num < len(doc) - 1:\n",
        "                full_text += \"\\n\\n--- End of Page {} ---\\n\\n\".format(page_num + 1)\n",
        "\n",
        "        doc.close()\n",
        "        return full_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing PDF file {pdf_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "print(\"PDF parsing function is defined.\")"
      ],
      "metadata": {
        "id": "bB4wIzzuZ6xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from typing import Dict, Any\n",
        "\n",
        "def write_summary_to_excel(resume_data: str, output_path: str = \"resume_summary.xlsx\") -> str:\n",
        "    \"\"\"\n",
        "    Writes the structured resume data (as a JSON string) to a formatted Excel file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # The LLM often returns a JSON string, so we parse it first\n",
        "        data_dict = json.loads(resume_data)\n",
        "\n",
        "        with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
        "            # --- Write Contact Info and Summary Sheet ---\n",
        "            contact_info = data_dict.get('contact_info', {})\n",
        "            summary = data_dict.get('summary', '')\n",
        "            summary_df = pd.DataFrame({\n",
        "                'Field': list(contact_info.keys()) + ['Summary'],\n",
        "                'Value': list(contact_info.values()) + [summary]\n",
        "            })\n",
        "            summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "            # --- Write Experience, Education, and Skills Sheets ---\n",
        "            for section in ['work_experience', 'education', 'skills']:\n",
        "                data = data_dict.get(section)\n",
        "                if data:\n",
        "                    df = pd.DataFrame(data)\n",
        "                    sheet_name = section.replace('_', ' ').title()\n",
        "                    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "            # --- Auto-format columns for readability ---\n",
        "            workbook = writer.book\n",
        "            for sheet_name in writer.sheets:\n",
        "                worksheet = writer.sheets[sheet_name]\n",
        "                for idx, col in enumerate(pd.read_excel(output_path, sheet_name=sheet_name).columns):\n",
        "                    series = pd.read_excel(output_path, sheet_name=sheet_name)[col]\n",
        "                    max_len = max((series.astype(str).map(len).max(), len(str(series.name)))) + 2\n",
        "                    worksheet.set_column(idx, idx, max_len)\n",
        "\n",
        "        return f\"Successfully created resume summary at {output_path}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error writing to Excel file: {e}\"\n",
        "\n",
        "print(\"Excel writer tool function is defined.\")"
      ],
      "metadata": {
        "id": "jEsGqNY_Z8F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import autogen\n",
        "from autogen.coding import LocalCommandLineCodeExecutor\n",
        "from pathlib import Path\n",
        "\n",
        "# Load the config list from the JSON file\n",
        "config_list = autogen.config_list_from_json(env_or_file=\"OAI_CONFIG_LIST.json\")\n",
        "llm_config = {\"config_list\": config_list}\n",
        "\n",
        "# --- Define the Parser Agent ---\n",
        "parser_agent = autogen.AssistantAgent(\n",
        "    name=\"ParserAgent\",\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"\"\"You are an expert HR analyst. Your task is to read resume text and extract key information into a structured JSON format.\n",
        "    You must call the 'write_summary_to_excel' function with the resulting JSON data.\n",
        "    Do not add any commentary or explanation outside of the final JSON object.\"\"\"\n",
        ")\n",
        "\n",
        "# --- Define the Analyzer Agent ---\n",
        "analyzer_agent = autogen.AssistantAgent(\n",
        "    name=\"AnalyzerAgent\",\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"\"\"You are an expert Data Analyst. Your function is to answer questions by writing and executing Python code.\n",
        "    Use the `pandas` library to analyze data from the provided Excel file.\n",
        "    First, formulate a plan. Then, write the Python code to answer the question.\n",
        "    The code will be executed for you, and you will receive the result. Use this result to formulate your final answer.\"\"\"\n",
        ")\n",
        "\n",
        "# --- Define the User Proxy Agent (our proxy) ---\n",
        "# Create a directory for the code execution\n",
        "work_dir = Path(\"coding\")\n",
        "work_dir.mkdir(exist_ok=True)\n",
        "executor = LocalCommandLineCodeExecutor(work_dir=work_dir)\n",
        "\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"UserProxy\",\n",
        "    human_input_mode=\"ALWAYS\",  # Critical for safety: ALWAYS ask for approval\n",
        "    code_execution_config={\"executor\": executor},\n",
        "    system_message=\"A human admin who will execute function calls and code after reviewing them.\"\n",
        ")\n",
        "\n",
        "print(\"All agents are defined.\")"
      ],
      "metadata": {
        "id": "XiE2Xr2IZ-rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload your resume PDF file.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the path of the uploaded file\n",
        "if uploaded:\n",
        "    # Take the first key from the 'uploaded' dictionary to get the filename string\n",
        "    resume_pdf_path = list(uploaded.keys())[0]\n",
        "    print(f\"\\nUploaded '{resume_pdf_path}' successfully.\")\n",
        "else:\n",
        "    print(\"\\nNo file uploaded. Please run this cell again to upload a file.\")\n",
        "    resume_pdf_path = None"
      ],
      "metadata": {
        "id": "bUD3aArYaACG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if resume_pdf_path:\n",
        "    print(\"--- Starting Step 1: Parsing Resume ---\")\n",
        "\n",
        "    # 1. Parse the resume PDF to get clean text\n",
        "    resume_text = parse_resume_with_pymupdf(resume_pdf_path)\n",
        "\n",
        "    if resume_text:\n",
        "        # 2. Define the schema for extraction\n",
        "        json_schema = \"\"\"\n",
        "        {\n",
        "          \"contact_info\": {\"name\": \"string\", \"email\": \"string\", \"phone\": \"string\", \"location\": \"string\"},\n",
        "          \"summary\": \"string\",\n",
        "          \"work_experience\": [{\"title\": \"string\", \"company\": \"string\", \"start_date\": \"string\", \"end_date\": \"string\", \"description\": \"string\"}],\n",
        "          \"education\": [{\"degree\": \"string\", \"institution\": \"string\", \"graduation_date\": \"string\"}],\n",
        "          \"skills\": [\"string\"]\n",
        "        }\n",
        "        \"\"\"\n",
        "\n",
        "        # 3. Formulate the task for the parser agent\n",
        "        parsing_task = f\"\"\"\n",
        "        Please parse the following resume text, extract the information according to the provided JSON schema, and then call the 'write_summary_to_excel' function with the extracted data.\n",
        "\n",
        "        JSON Schema:\n",
        "        {json_schema}\n",
        "\n",
        "        Resume Text:\n",
        "        ---\n",
        "        {resume_text}\n",
        "        ---\n",
        "        \"\"\"\n",
        "\n",
        "        # 4. Register the tool with the User Proxy\n",
        "        user_proxy.register_function(\n",
        "            function_map={\n",
        "                \"write_summary_to_excel\": write_summary_to_excel\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # 5. Initiate the chat for parsing\n",
        "        user_proxy.initiate_chat(\n",
        "            recipient=parser_agent,\n",
        "            message=parsing_task\n",
        "        )\n",
        "    else:\n",
        "        print(\"Failed to extract text from PDF. Aborting.\")\n",
        "else:\n",
        "    print(\"Please upload a resume in the previous step before running this cell.\")"
      ],
      "metadata": {
        "id": "I7d1pPxxaBmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_excel_path = \"resume_summary.xlsx\"\n",
        "\n",
        "if Path(output_excel_path).exists():\n",
        "    print(f\"\\n--- Step 1 Complete. Summary saved to {output_excel_path} ---\")\n",
        "    print(\"--- Starting Step 2: Analyzing Data ---\")\n",
        "\n",
        "    # Formulate the task for the analyzer agent\n",
        "    analysis_task = f\"\"\"\n",
        "    Read the candidate data from the Excel file located at '{output_excel_path}'.\n",
        "    Then, please answer the following questions:\n",
        "    1. What is the candidate's most recent job title? (Hint: Look at the 'Experience' sheet).\n",
        "    2. How many unique skills are listed? (Hint: Look at the 'Skills' sheet).\n",
        "    \"\"\"\n",
        "\n",
        "    # Initiate the chat for analysis\n",
        "    user_proxy.initiate_chat(\n",
        "        recipient=analyzer_agent,\n",
        "        message=analysis_task\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Step 2 Complete. Analysis finished. ---\")\n",
        "else:\n",
        "    print(\"Excel summary file was not created. Cannot proceed with analysis.\")"
      ],
      "metadata": {
        "id": "jRwBJOLfaDNn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}